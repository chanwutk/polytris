{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c12ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to video and annotation files\n",
    "video_path = '/otif-dataset/dataset/amsterdam/train/video/0.mp4'\n",
    "annotation_path = '/otif-dataset/dataset/amsterdam/train/yolov3-1280x736/0.json'\n",
    "output_video_path = './0_annotated.mp4'\n",
    "\n",
    "# Load annotation file\n",
    "with open(annotation_path, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Print annotation structure to understand the format\n",
    "print(\"Annotation keys:\", annotations.keys() if isinstance(annotations, dict) else \"List with\", len(annotations), \"items\")\n",
    "if isinstance(annotations, dict):\n",
    "    print(\"Sample keys:\", list(annotations.keys())[:5])\n",
    "    if 'annotations' in annotations:\n",
    "        print(\"Sample annotation:\", annotations['annotations'][0] if annotations['annotations'] else \"Empty\")\n",
    "elif isinstance(annotations, list):\n",
    "    print(\"Sample item:\", annotations[0] if annotations else \"Empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), f\"Could not open video {video_path}\"\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video properties: {width}x{height}, {fps} FPS, {frame_count} frames\")\n",
    "\n",
    "# Create video writer\n",
    "fourcc = cv2.VideoWriter.fourcc('m', 'p', '4', 'v')\n",
    "writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "assert writer.isOpened(), f\"Could not create video writer for {output_video_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bfdb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse annotations into a dictionary keyed by frame index\n",
    "# Handle different annotation formats\n",
    "frame_annotations = {}\n",
    "\n",
    "if isinstance(annotations, dict):\n",
    "    # COCO format or similar\n",
    "    if 'annotations' in annotations and 'images' in annotations:\n",
    "        # COCO format: map image_id to frame_index, then annotations to frames\n",
    "        image_id_to_frame = {}\n",
    "        for img in annotations['images']:\n",
    "            # Try to extract frame index from filename or use image_id\n",
    "            if 'frame_index' in img:\n",
    "                image_id_to_frame[img['id']] = img['frame_index']\n",
    "            elif 'file_name' in img:\n",
    "                # Try to extract frame number from filename\n",
    "                filename = img['file_name']\n",
    "                try:\n",
    "                    frame_idx = int(filename.split('_')[-1].split('.')[0])\n",
    "                    image_id_to_frame[img['id']] = frame_idx\n",
    "                except:\n",
    "                    image_id_to_frame[img['id']] = img['id']\n",
    "            else:\n",
    "                image_id_to_frame[img['id']] = img['id']\n",
    "        \n",
    "        # Group annotations by frame\n",
    "        for ann in annotations['annotations']:\n",
    "            image_id = ann['image_id']\n",
    "            frame_idx = image_id_to_frame.get(image_id, image_id)\n",
    "            if frame_idx not in frame_annotations:\n",
    "                frame_annotations[frame_idx] = []\n",
    "            \n",
    "            # Extract bbox: COCO format is [x, y, width, height]\n",
    "            bbox = ann['bbox']\n",
    "            x, y, w, h = bbox\n",
    "            # Convert to [x1, y1, x2, y2] format\n",
    "            frame_annotations[frame_idx].append([x, y, x + w, y + h])\n",
    "    elif 'frames' in annotations:\n",
    "        # Custom format with frames key\n",
    "        for frame_data in annotations['frames']:\n",
    "            frame_idx = frame_data.get('frame_idx', frame_data.get('frame_index', 0))\n",
    "            frame_annotations[frame_idx] = frame_data.get('boxes', frame_data.get('detections', []))\n",
    "    else:\n",
    "        # Dictionary with frame indices as keys\n",
    "        frame_annotations = annotations\n",
    "elif isinstance(annotations, list):\n",
    "    # List format: each item is a frame annotation\n",
    "    for idx, frame_ann in enumerate(annotations):\n",
    "        if isinstance(frame_ann, dict):\n",
    "            frame_idx = frame_ann.get('frame_idx', frame_ann.get('frame_index', idx))\n",
    "            frame_annotations[frame_idx] = frame_ann.get('boxes', frame_ann.get('detections', frame_ann.get('annotations', [])))\n",
    "        elif isinstance(frame_ann, list):\n",
    "            # Direct list of boxes\n",
    "            frame_annotations[idx] = frame_ann\n",
    "\n",
    "print(f\"Loaded annotations for {len(frame_annotations)} frames\")\n",
    "print(f\"Frame indices range: {min(frame_annotations.keys()) if frame_annotations else 'N/A'} to {max(frame_annotations.keys()) if frame_annotations else 'N/A'}\")\n",
    "if frame_annotations:\n",
    "    sample_frame = list(frame_annotations.keys())[0]\n",
    "    print(f\"Sample frame {sample_frame} has {len(frame_annotations[sample_frame])} annotations\")\n",
    "    if frame_annotations[sample_frame]:\n",
    "        print(f\"Sample annotation format: {frame_annotations[sample_frame][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reopen video for processing (since we already read properties)\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Process each frame and draw bounding boxes\n",
    "frame_idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Get annotations for this frame\n",
    "    boxes = frame_annotations.get(frame_idx, [])\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for box in boxes:\n",
    "        # Handle different box formats\n",
    "        if isinstance(box, dict):\n",
    "            # Dictionary format with keys like 'left', 'top', 'right', 'bottom'\n",
    "            if 'left' in box and 'top' in box and 'right' in box and 'bottom' in box:\n",
    "                x1, y1, x2, y2 = box['left'], box['top'], box['right'], box['bottom']\n",
    "            elif 'x1' in box and 'y1' in box and 'x2' in box and 'y2' in box:\n",
    "                x1, y1, x2, y2 = box['x1'], box['y1'], box['x2'], box['y2']\n",
    "            elif 'x' in box and 'y' in box and 'width' in box and 'height' in box:\n",
    "                # COCO format: [x, y, width, height]\n",
    "                x1 = box['x']\n",
    "                y1 = box['y']\n",
    "                x2 = x1 + box['width']\n",
    "                y2 = y1 + box['height']\n",
    "            else:\n",
    "                continue\n",
    "        elif isinstance(box, (list, tuple)) and len(box) >= 4:\n",
    "            if len(box) == 4:\n",
    "                # [x1, y1, x2, y2] or [x, y, w, h]\n",
    "                x1, y1, x2_or_w, y2_or_h = box\n",
    "                # Check if it's [x, y, w, h] or [x1, y1, x2, y2]\n",
    "                if x2_or_w < x1 or y2_or_h < y1:\n",
    "                    # Likely [x, y, w, h] format\n",
    "                    x1, y1, w, h = box\n",
    "                    x2, y2 = x1 + w, y1 + h\n",
    "                else:\n",
    "                    # [x1, y1, x2, y2] format\n",
    "                    x1, y1, x2, y2 = box\n",
    "            else:\n",
    "                # [track_id, x1, y1, x2, y2] or similar\n",
    "                x1, y1, x2, y2 = box[-4:]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Convert to integers\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "        # Draw bounding box in green\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    # Write frame to output video\n",
    "    writer.write(frame)\n",
    "    \n",
    "    frame_idx += 1\n",
    "    \n",
    "    if frame_idx % 100 == 0:\n",
    "        print(f\"Processed {frame_idx}/{frame_count} frames\")\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "print(f\"Video saved to {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17564431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert video to H.264 codec using ffmpeg\n",
    "h264_output_path = output_video_path.replace('.mp4', '.h264.mp4')\n",
    "\n",
    "# Run FFMPEG command to convert to H.264\n",
    "cmd = [\n",
    "    'ffmpeg', '-y',  # -y to overwrite output file\n",
    "    '-loglevel', 'quiet',  # silence FFMPEG output\n",
    "    '-i', output_video_path,  # input file\n",
    "    '-c:v', 'libx264',  # H.264 codec\n",
    "    '-preset', 'fast',  # encoding preset\n",
    "    '-crf', '28',  # constant rate factor (lower quality, smaller file)\n",
    "    '-profile:v', 'baseline',  # baseline profile for better compatibility\n",
    "    '-level', '3.0',  # H.264 level for broader device support\n",
    "    '-movflags', '+faststart',  # optimize for streaming/web playback\n",
    "    '-pix_fmt', 'yuv420p',  # pixel format for maximum compatibility\n",
    "    '-tune', 'fastdecode',  # optimize for faster decoding\n",
    "    h264_output_path\n",
    "]\n",
    "\n",
    "print(f\"Converting {output_video_path} to H.264 format...\")\n",
    "subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "print(f\"H.264 video saved to {h264_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262af8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
