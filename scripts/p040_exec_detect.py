#!/usr/local/bin/python

import argparse
import json
import os
import shutil
import time
import cv2
import multiprocessing as mp
from functools import partial
from typing import Callable
import torch

import polyis.models.detector
import polyis.dtypes
from polyis.utilities import TILEPADDING_MODES, TilePadding, format_time, ProgressBar, get_config


config = get_config()
CACHE_DIR = config['DATA']['CACHE_DIR']
DATASETS_DIR = config['DATA']['DATASETS_DIR']
CLASSIFIERS = config['EXEC']['CLASSIFIERS']
TILE_SIZES = config['EXEC']['TILE_SIZES']
DATASETS = config['EXEC']['DATASETS']


def parse_args():
    parser = argparse.ArgumentParser(description='Detect objects from packed images generated by 030_exec_pack.py')
    parser.add_argument('--clear', action='store_true',
                        help='Remove and recreate the 040_compressed_detections folder for each video')
    parser.add_argument('--batch_size', type=int, default=16,
                        help='Batch size for detection processing (default: 16)')
    return parser.parse_args()


def detect_objects(dataset: str, video: str, classifier: str, tilesize: int,
                   tilepadding: TilePadding, batch_size: int, gpu_id: int, command_queue: mp.Queue):
    """
    Detect objects in compressed images using auto-selected detector.
    
    Args:
        dataset_name (str): Name of the dataset (used to auto-select detector)
        video (str): Name of the video file
        classifier (str): Classifier name used for compression
        tilesize (int): Tile size used for compression
        tilepadding (TilePadding): Whether padding was applied to classification results
        gpu_id (int): GPU ID to use for processing
        command_queue (mp.Queue): Queue for progress updates
    """
    device = f'cuda:{gpu_id}'
    cache_dir = os.path.join(CACHE_DIR, dataset, 'execution', video)
    param_str = f'{classifier}_{tilesize}_{tilepadding}'
    
    compressed_frames_dir = os.path.join(cache_dir, '033_compressed_frames', param_str, 'images')
    assert os.path.exists(compressed_frames_dir), \
        f"Compressed frames directory {compressed_frames_dir} does not exist"

    # Create output directory for detections
    detections_output_dir = os.path.join(cache_dir, '040_compressed_detections', param_str)
    if os.path.exists(detections_output_dir):
        # Remove the entire directory
        shutil.rmtree(detections_output_dir)
    os.makedirs(detections_output_dir, exist_ok=True)

    # Get all compressed image files
    image_files = [f for f in os.listdir(compressed_frames_dir) if f.endswith('.jpg')]

    detector = polyis.models.detector.get_detector(dataset, gpu_id, batch_size, len(image_files))

    with (open(os.path.join(detections_output_dir, 'detections.jsonl'), 'w') as f,
          open(os.path.join(detections_output_dir, 'runtimes.jsonl'), 'w') as fr,
          torch.no_grad()):
        description = f"{dataset} {video} {tilesize:>3} {classifier[:3]} {tilepadding[:3]}"
        kwargs = {'completed': 0, 'total': len(image_files), 'description': description}
        command_queue.put((device, kwargs))

        # Warm up
        for batch_start in range(0, min(4, len(image_files)), batch_size):
            batch_end = min(batch_start + batch_size, len(image_files))
            batch_files = image_files[batch_start:batch_end]
            
            # Read all images in the batch
            batch_images_: list[polyis.dtypes.NPImage] = []
            for image_file in batch_files:
                image_path = os.path.join(compressed_frames_dir, image_file)
                frame = cv2.imread(image_path)
                assert frame is not None
                assert polyis.dtypes.is_np_image(frame)
                batch_images_.append(frame)
            batch_outputs = polyis.models.detector.detect_batch(batch_images_, detector)
        torch.cuda.synchronize()
        
        # Process images in batches
        for batch_start in range(0, len(image_files), batch_size):
            batch_end = min(batch_start + batch_size, len(image_files))
            batch_files = image_files[batch_start:batch_end]
            
            # Read all images in the batch
            batch_images: list[polyis.dtypes.NPImage] = []
            batch_runtimes: list[dict] = []
            start_time = (time.time_ns() / 1e6)
            for image_file in batch_files:
                image_path = os.path.join(compressed_frames_dir, image_file)
                frame = cv2.imread(image_path)
                assert frame is not None
                assert polyis.dtypes.is_np_image(frame)
                batch_images.append(frame)
                batch_runtimes.append({'image_file': image_file})
            end_time = (time.time_ns() / 1e6)
            read_time_per_image = (end_time - start_time) / len(batch_files)

            # Detect objects in the batch
            start_time = (time.time_ns() / 1e6)
            batch_outputs = polyis.models.detector.detect_batch(batch_images, detector)
            end_time = (time.time_ns() / 1e6)
            detect_time_per_image = (end_time - start_time) / len(batch_files)

            # Process results for each image in the batch
            for idx, (image_file, outputs) in enumerate(zip(batch_files, batch_outputs)):
                runtime = batch_runtimes[idx]
                runtime['read'] = read_time_per_image
                runtime['detect'] = detect_time_per_image

                # Extract bounding boxes (x1, y1, x2, y2) format
                bounding_boxes = outputs[:, :4].tolist()

                # Save detection results
                f.write(json.dumps({ 'image_file': image_file, 'bboxes': bounding_boxes }) + '\n')
                fr.write(json.dumps(format_time(**runtime)) + '\n')

            command_queue.put((device, {'completed': batch_end + 1}))


def main(args):
    """
    Main function that orchestrates the object detection process on compressed images using parallel processing.
    
    This function serves as the entry point for the script. It:
    1. Validates the dataset directories exist
    2. Creates a list of all video/classifier/tilesize combinations to process
    3. Uses multiprocessing to process tasks in parallel across available GPUs
    4. Processes each video and saves detection results
    
    Args:
        args (argparse.Namespace): Parsed command line arguments containing:
            - clear (bool): Whether to remove and recreate the 040_compressed_detections folder for each video
            
    Note:
        - The script expects compressed images from 030_exec_compress.py in:
          {CACHE_DIR}/{dataset}/execution/{video_file}/030_compressed_frames/{classifier}_{tilesize}/images/
        - Detection results are saved to:
          {CACHE_DIR}/{dataset}/execution/{video_file}/040_compressed_detections/{classifier}_{tilesize}/detections.jsonl
        - Each line in the output JSONL file contains one bounding box [x1, y1, x2, y2]
        - When tilesize is 'all', all available tile sizes are processed
        - When classifiers is not specified, all classifiers in CLASSIFIERS_TO_TEST + ['Perfect'] are processed
        - If no compressed images are found for a video/tilesize/classifier combination, that combination is skipped
        - The number of processes equals the number of available GPUs
    """
    mp.set_start_method('spawn', force=True)
    
    # Create tasks list with all video/classifier/tilesize combinations
    funcs: list[Callable[[int, mp.Queue], None]] = []

    if args.clear:
        print(f"Cleared existing 040_compressed_detections folder")
        for dataset in DATASETS:
            cache_dir = os.path.join(CACHE_DIR, dataset, 'execution')
            for video in sorted(os.listdir(cache_dir)):
                compressed_detections_dir = os.path.join(cache_dir, video,
                                                         '040_compressed_detections')
                if os.path.exists(compressed_detections_dir):
                    shutil.rmtree(compressed_detections_dir)
    
    for dataset in DATASETS:
        videoset_dir = os.path.join(DATASETS_DIR, dataset, 'test')
        for video in sorted(os.listdir(videoset_dir)):
            for classifier in CLASSIFIERS:
                for tilesize in TILE_SIZES:
                    for tilepadding in TILEPADDING_MODES:
                        funcs.append(partial(detect_objects, dataset, video, classifier,
                                             tilesize, tilepadding, args.batch_size))
    
    print(f"Created {len(funcs)} tasks to process")
    
    # Set up multiprocessing with ProgressBar
    # Use number of available GPUs as the number of processes
    num_gpus = torch.cuda.device_count()
    assert num_gpus > 0, "No GPUs available"
    print(f"Using {num_gpus} GPUs for parallel processing")
    
    if len(funcs) < num_gpus:
        num_gpus = len(funcs)
    
    ProgressBar(num_workers=num_gpus, num_tasks=len(funcs)).run_all(funcs)
    print("All tasks completed!")


if __name__ == '__main__':
    main(parse_args())
