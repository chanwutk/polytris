#!/usr/local/bin/python

import argparse
import json
import os
import shutil
import time
import cv2
import multiprocessing as mp
from functools import partial
from typing import Callable
import torch

import polyis.models.detector
import polyis.dtypes
from polyis.utilities import CACHE_DIR, format_time, CLASSIFIERS_CHOICES, ProgressBar, DATASETS_TO_TEST, TILE_SIZES, CLASSIFIERS_TO_TEST


def parse_args():
    parser = argparse.ArgumentParser(description='Detect objects from packed images generated by 030_exec_pack.py')
    parser.add_argument('--datasets', required=False,
                        default=DATASETS_TO_TEST,
                        nargs='+',
                        help='Dataset names (space-separated)')
    parser.add_argument('--tilesize', type=str, choices=['30', '60', '120', 'all'], default='all',
                        help='Tile size to use for detection (or "all" for all tile sizes)')
    # Detector selection is now automatic based on dataset name
    parser.add_argument('--classifiers', required=False,
                        default=CLASSIFIERS_TO_TEST + ['Perfect'],
                        choices=CLASSIFIERS_CHOICES + ['Perfect'],
                        nargs='+',
                        help='Classifier names to use (can specify multiple): '
                             f'{", ".join(CLASSIFIERS_CHOICES + ["Perfect"])}. For example: '
                             '--classifiers YoloN ShuffleNet05 ResNet18 groundtruth')
    parser.add_argument('--clear', action='store_true',
                        help='Remove and recreate the 040_compressed_detections folder for each video')
    parser.add_argument('--batch_size', type=int, default=64,
                        help='Batch size for detection processing (default: 64)')
    return parser.parse_args()


def detect_objects(video_file_path: str, tilesize: int, classifier: str, dataset_name: str,
                   tilepadding: bool, batch_size: int, gpu_id: int, command_queue: mp.Queue):
    """
    Detect objects in compressed images using auto-selected detector.
    
    Args:
        video_file_path (str): Path to the video file
        tilesize (int): Tile size used for compression
        classifier (str): Classifier name used for compression
        dataset_name (str): Name of the dataset (used to auto-select detector)
        tilepadding (bool): Whether padding was applied to classification results
        gpu_id (int): GPU ID to use for processing
        command_queue (mp.Queue): Queue for progress updates
    """
    device = f'cuda:{gpu_id}'
    tilepadding_str = "padded" if tilepadding else "unpadded"
    video_name = os.path.basename(video_file_path)
    
    compressed_frames_dir = os.path.join(video_file_path, '030_compressed_frames',
                                         f'{classifier}_{tilesize}_{tilepadding_str}', 'images')
    assert os.path.exists(compressed_frames_dir)

    # print(f"Processing video {video_file_path}")

    # Create output directory for detections
    detections_output_dir = os.path.join(video_file_path, '040_compressed_detections', f'{classifier}_{tilesize}_{tilepadding_str}')
    if os.path.exists(detections_output_dir):
        # Remove the entire directory
        shutil.rmtree(detections_output_dir)
    os.makedirs(detections_output_dir, exist_ok=True)

    # Get all compressed image files
    image_files = [f for f in os.listdir(compressed_frames_dir) if f.endswith('.jpg')]

    detector = polyis.models.detector.get_detector(dataset_name, gpu_id, batch_size, len(image_files))
    
    if not image_files:
        raise FileNotFoundError(f"No compressed images found in {compressed_frames_dir}")

    with (open(os.path.join(detections_output_dir, 'detections.jsonl'), 'w') as f,
          open(os.path.join(detections_output_dir, 'runtimes.jsonl'), 'w') as fr):
        kwargs = {'completed': 0,
                  'total': len(image_files),
                  'description': f"{video_name} {tilesize:>3} {classifier} {tilepadding_str}"}
        command_queue.put((device, kwargs))
        
        # Process images in batches
        for batch_start in range(0, len(image_files), batch_size):
            batch_end = min(batch_start + batch_size, len(image_files))
            batch_files = image_files[batch_start:batch_end]
            
            # Read all images in the batch
            batch_images: list[polyis.dtypes.NPImage] = []
            batch_runtimes: list[dict] = []
            start_time = (time.time_ns() / 1e6)
            for image_file in batch_files:
                image_path = os.path.join(compressed_frames_dir, image_file)
                frame = cv2.imread(image_path)
                assert polyis.dtypes.is_np_image(frame)
                batch_images.append(frame)
                batch_runtimes.append({'image_file': image_file})
            end_time = (time.time_ns() / 1e6)
            read_time_per_image = (end_time - start_time) / len(batch_files)

            # Detect objects in the batch
            start_time = (time.time_ns() / 1e6)
            batch_outputs = polyis.models.detector.detect_batch(batch_images, detector)
            end_time = (time.time_ns() / 1e6)
            detect_time_per_image = (end_time - start_time) / len(batch_files)

            # Process results for each image in the batch
            for idx, (image_file, outputs) in enumerate(zip(batch_files, batch_outputs)):
                runtime = batch_runtimes[idx]
                runtime['read'] = read_time_per_image
                runtime['detect'] = detect_time_per_image

                # Extract bounding boxes (x1, y1, x2, y2) format
                bounding_boxes = outputs[:, :4].tolist()

                # Save detection results
                f.write(json.dumps({ 'image_file': image_file, 'bboxes': bounding_boxes }) + '\n')
                fr.write(json.dumps(format_time(**runtime)) + '\n')

            command_queue.put((device, {'completed': batch_end + 1}))


def main(args):
    """
    Main function that orchestrates the object detection process on compressed images using parallel processing.
    
    This function serves as the entry point for the script. It:
    1. Validates the dataset directories exist
    2. Creates a list of all video/classifier/tilesize combinations to process
    3. Uses multiprocessing to process tasks in parallel across available GPUs
    4. Processes each video and saves detection results
    
    Args:
        args (argparse.Namespace): Parsed command line arguments containing:
            - datasets (List[str]): Names of the datasets to process
            - tilesize (str): Tile size to use for detection ('30', '60', '120', or 'all')
            - detector: Detector is auto-selected based on dataset name
            - classifiers (list): List of classifier names to use (default: CLASSIFIERS_TO_TEST + ['Perfect'])
            - clear (bool): Whether to remove and recreate the 040_compressed_detections folder for each video
            
    Note:
        - The script expects compressed images from 030_exec_compress.py in:
          {CACHE_DIR}/{dataset}/execution/{video_file}/030_compressed_frames/{classifier}_{tilesize}/images/
        - Detection results are saved to:
          {CACHE_DIR}/{dataset}/execution/{video_file}/040_compressed_detections/{classifier}_{tilesize}/detections.jsonl
        - Each line in the output JSONL file contains one bounding box [x1, y1, x2, y2]
        - When tilesize is 'all', all available tile sizes are processed
        - When classifiers is not specified, all classifiers in CLASSIFIERS_TO_TEST + ['Perfect'] are processed
        - If no compressed images are found for a video/tilesize/classifier combination, that combination is skipped
        - The number of processes equals the number of available GPUs
    """
    mp.set_start_method('spawn', force=True)
    
    # Determine which tile sizes to process
    if args.tilesize == 'all':
        tilesizes_to_process = TILE_SIZES
        print(f"Processing all tile sizes: {tilesizes_to_process}")
    else:
        tilesizes_to_process = [int(args.tilesize)]
        print(f"Processing tile size: {tilesizes_to_process[0]}")
    
    # Determine which classifiers to process
    classifiers_to_process = args.classifiers
    
    # Create tasks list with all video/classifier/tilesize combinations
    funcs: list[Callable[[int, mp.Queue], None]] = []
    
    for dataset_name in args.datasets:
        dataset_dir = os.path.join(CACHE_DIR, dataset_name, 'execution')
        
        if not os.path.exists(dataset_dir):
            print(f"Dataset directory {dataset_dir} does not exist, skipping...")
            continue
        
        # Show detector info for this dataset
        detector_info = polyis.models.detector.get_detector_info(dataset_name)
        print(f"Using detector: {detector_info['detector']} ({detector_info['description']})")
        
        # Get all video files from the dataset directory
        video_files = [f for f in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, f))]
        
        for video_file in sorted(video_files):
            video_file_path = os.path.join(dataset_dir, video_file)
            
            # Clear compressed detections folder if requested
            if args.clear:
                compressed_detections_base_dir = os.path.join(video_file_path, '040_compressed_detections')
                if os.path.exists(compressed_detections_base_dir):
                    shutil.rmtree(compressed_detections_base_dir)
                    print(f"Cleared existing 040_compressed_detections folder: {compressed_detections_base_dir}")
            
            for classifier in classifiers_to_process:
                for tilesize in tilesizes_to_process:
                    for tilepadding in [True, False]:
                        tilepadding_str = "padded" if tilepadding else "unpadded"
                        # Check if compressed frames directory exists
                        compressed_frames_dir = os.path.join(video_file_path, '030_compressed_frames',
                                                             f'{classifier}_{tilesize}_{tilepadding_str}', 'images')
                        if not os.path.exists(compressed_frames_dir):
                            print(f"No compressed frames directory found for {video_file} {classifier} {tilesize}, skipping")
                            continue
                    
                        funcs.append(partial(detect_objects, video_file_path, tilesize, classifier,
                                             dataset_name, tilepadding, args.batch_size))
    
    print(f"Created {len(funcs)} tasks to process")
    
    # Set up multiprocessing with ProgressBar
    # Use number of available GPUs as the number of processes
    num_gpus = torch.cuda.device_count()
    assert num_gpus > 0, "No GPUs available"
    print(f"Using {num_gpus} GPUs for parallel processing")
    
    if len(funcs) < num_gpus:
        num_gpus = len(funcs)
    
    ProgressBar(num_workers=num_gpus, num_tasks=len(funcs)).run_all(funcs)
    print("All tasks completed!")


if __name__ == '__main__':
    main(parse_args())
