#!/usr/local/bin/python

import argparse
import json
import os
import shutil
import time
import cv2
import multiprocessing as mp
from functools import partial
from typing import Callable
import torch

import polyis.models.detector
import polyis.dtypes
from polyis.utilities import CACHE_DIR, CLASSIFIERS, DATASETS_DIR, TILEPADDING_MODES, TilePadding, format_time, ProgressBar, DATASETS_TO_TEST, TILE_SIZES


def parse_args():
    parser = argparse.ArgumentParser(description='Detect objects from packed images generated by 030_exec_pack.py')
    parser.add_argument('--datasets', required=False,
                        default=DATASETS_TO_TEST,
                        nargs='+',
                        help='Dataset names (space-separated)')
    parser.add_argument('--clear', action='store_true',
                        help='Remove and recreate the 040_compressed_detections folder for each video')
    parser.add_argument('--batch_size', type=int, default=16,
                        help='Batch size for detection processing (default: 16)')
    return parser.parse_args()


def detect_objects(video_name: str, tilesize: int, classifier: str, dataset: str,
                   tilepadding: TilePadding, batch_size: int, gpu_id: int, command_queue: mp.Queue):
    """
    Detect objects in compressed images using auto-selected detector.
    
    Args:
        video_name (str): Name of the video file
        tilesize (int): Tile size used for compression
        classifier (str): Classifier name used for compression
        dataset_name (str): Name of the dataset (used to auto-select detector)
        tilepadding (bool): Whether padding was applied to classification results
        gpu_id (int): GPU ID to use for processing
        command_queue (mp.Queue): Queue for progress updates
    """
    device = f'cuda:{gpu_id}'
    cache_dir = os.path.join(CACHE_DIR, dataset, 'execution', video_name)
    param_str = f'{classifier}_{tilesize}_{tilepadding}'
    
    compressed_frames_dir = os.path.join(cache_dir, '031_compressed_frames', param_str, 'images')
    assert os.path.exists(compressed_frames_dir)

    # Create output directory for detections
    detections_output_dir = os.path.join(cache_dir, '040_compressed_detections', param_str)
    if os.path.exists(detections_output_dir):
        # Remove the entire directory
        shutil.rmtree(detections_output_dir)
    os.makedirs(detections_output_dir, exist_ok=True)

    # Get all compressed image files
    image_files = [f for f in os.listdir(compressed_frames_dir) if f.endswith('.jpg')]

    detector = polyis.models.detector.get_detector(dataset, gpu_id, batch_size, len(image_files))
    
    if not image_files:
        raise FileNotFoundError(f"No compressed images found in {compressed_frames_dir}")

    with (open(os.path.join(detections_output_dir, 'detections.jsonl'), 'w') as f,
          open(os.path.join(detections_output_dir, 'runtimes.jsonl'), 'w') as fr):
        description = f"{dataset} {video_name} {tilesize:>3} {classifier[:3]} {tilepadding[:3]}"
        kwargs = {'completed': 0, 'total': len(image_files), 'description': description}
        command_queue.put((device, kwargs))
        
        # Process images in batches
        for batch_start in range(0, len(image_files), batch_size):
            batch_end = min(batch_start + batch_size, len(image_files))
            batch_files = image_files[batch_start:batch_end]
            
            # Read all images in the batch
            batch_images: list[polyis.dtypes.NPImage] = []
            batch_runtimes: list[dict] = []
            start_time = (time.time_ns() / 1e6)
            for image_file in batch_files:
                image_path = os.path.join(compressed_frames_dir, image_file)
                frame = cv2.imread(image_path)
                assert polyis.dtypes.is_np_image(frame)
                batch_images.append(frame)
                batch_runtimes.append({'image_file': image_file})
            end_time = (time.time_ns() / 1e6)
            read_time_per_image = (end_time - start_time) / len(batch_files)

            # Detect objects in the batch
            start_time = (time.time_ns() / 1e6)
            batch_outputs = polyis.models.detector.detect_batch(batch_images, detector)
            end_time = (time.time_ns() / 1e6)
            detect_time_per_image = (end_time - start_time) / len(batch_files)

            # Process results for each image in the batch
            for idx, (image_file, outputs) in enumerate(zip(batch_files, batch_outputs)):
                runtime = batch_runtimes[idx]
                runtime['read'] = read_time_per_image
                runtime['detect'] = detect_time_per_image

                # Extract bounding boxes (x1, y1, x2, y2) format
                bounding_boxes = outputs[:, :4].tolist()

                # Save detection results
                f.write(json.dumps({ 'image_file': image_file, 'bboxes': bounding_boxes }) + '\n')
                fr.write(json.dumps(format_time(**runtime)) + '\n')

            command_queue.put((device, {'completed': batch_end + 1}))


def main(args):
    """
    Main function that orchestrates the object detection process on compressed images using parallel processing.
    
    This function serves as the entry point for the script. It:
    1. Validates the dataset directories exist
    2. Creates a list of all video/classifier/tilesize combinations to process
    3. Uses multiprocessing to process tasks in parallel across available GPUs
    4. Processes each video and saves detection results
    
    Args:
        args (argparse.Namespace): Parsed command line arguments containing:
            - datasets (List[str]): Names of the datasets to process
            - tilesize (str): Tile size to use for detection ('30', '60', '120', or 'all')
            - detector: Detector is auto-selected based on dataset name
            - classifiers (list): List of classifier names to use (default: CLASSIFIERS_TO_TEST + ['Perfect'])
            - clear (bool): Whether to remove and recreate the 040_compressed_detections folder for each video
            
    Note:
        - The script expects compressed images from 030_exec_compress.py in:
          {CACHE_DIR}/{dataset}/execution/{video_file}/030_compressed_frames/{classifier}_{tilesize}/images/
        - Detection results are saved to:
          {CACHE_DIR}/{dataset}/execution/{video_file}/040_compressed_detections/{classifier}_{tilesize}/detections.jsonl
        - Each line in the output JSONL file contains one bounding box [x1, y1, x2, y2]
        - When tilesize is 'all', all available tile sizes are processed
        - When classifiers is not specified, all classifiers in CLASSIFIERS_TO_TEST + ['Perfect'] are processed
        - If no compressed images are found for a video/tilesize/classifier combination, that combination is skipped
        - The number of processes equals the number of available GPUs
    """
    mp.set_start_method('spawn', force=True)
    
    # Create tasks list with all video/classifier/tilesize combinations
    funcs: list[Callable[[int, mp.Queue], None]] = []

    if args.clear:
        print(f"Cleared existing 040_compressed_detections folder")
        for dataset in args.datasets:
            cache_dir = os.path.join(CACHE_DIR, dataset, 'execution')
            for video_file in sorted(os.listdir(cache_dir)):
                compressed_detections_dir = os.path.join(cache_dir, video_file,
                                                         '040_compressed_detections')
                if os.path.exists(compressed_detections_dir):
                    shutil.rmtree(compressed_detections_dir)
    
    for dataset in args.datasets:
        videoset_dir = os.path.join(DATASETS_DIR, dataset, 'test')
        for video_file in sorted(os.listdir(videoset_dir)):
            for classifier in CLASSIFIERS:
                for tilesize in TILE_SIZES:
                    for tilepadding in TILEPADDING_MODES:
                        funcs.append(partial(detect_objects, video_file, tilesize, classifier,
                                             dataset, tilepadding, args.batch_size))
    
    print(f"Created {len(funcs)} tasks to process")
    
    # Set up multiprocessing with ProgressBar
    # Use number of available GPUs as the number of processes
    num_gpus = torch.cuda.device_count()
    assert num_gpus > 0, "No GPUs available"
    print(f"Using {num_gpus} GPUs for parallel processing")
    
    if len(funcs) < num_gpus:
        num_gpus = len(funcs)
    
    ProgressBar(num_workers=num_gpus, num_tasks=len(funcs)).run_all(funcs)
    print("All tasks completed!")


if __name__ == '__main__':
    main(parse_args())
