#!/usr/bin/env python3
"""
Script to compare compression results across different configurations.

This script analyzes compressed frames generated by p030_exec_compress.py and
creates two comparison tables:
1. Number of compressed images for each (dataset, classifier, tilesize, tilepadding)
2. Number of empty vs occupied tiles for each configuration
"""

import argparse
from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd
from tqdm import tqdm

from polyis.utilities import CACHE_DIR, DATASETS_TO_TEST, get_video_frame_count


INPUT_DIR = '030_compressed_frames'
OUTPUT_DIR = '085_compress_single'


def parse_args():
    parser = argparse.ArgumentParser(
        description='Compare compression results across different configurations'
    )
    parser.add_argument(
        '--datasets',
        nargs='+',
        default=DATASETS_TO_TEST,
        help='Datasets to analyze (default: all datasets in DATASETS_TO_TEST)'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Print verbose output'
    )
    return parser.parse_args()


def build_config_paths_dataframe(datasets: List[str], verbose: bool = False) -> pd.DataFrame:
    """
    Build a DataFrame containing all configuration paths across datasets.

    Args:
        datasets: List of dataset names
        verbose: Whether to print verbose output

    Returns:
        DataFrame with columns: dataset, video, config_path, config_name
    """
    # Collect all configuration paths
    config_records = []

    # Scan all datasets, videos, and configurations
    for dataset in datasets:
        dataset_cache_dir = Path(CACHE_DIR) / dataset / 'execution'

        if not dataset_cache_dir.is_dir():
            if verbose:
                print(f"Dataset cache directory not found: {dataset_cache_dir}")
            continue

        # Find all video directories with compressed frames
        for video_dir in dataset_cache_dir.iterdir():
            if not video_dir.is_dir():
                continue

            compressed_frames_dir = video_dir / INPUT_DIR
            if not compressed_frames_dir.is_dir():
                continue

            video_name = video_dir.name

            # Find all configuration directories
            for config_dir in compressed_frames_dir.iterdir():
                if not config_dir.is_dir():
                    continue

                config_records.append({
                    'dataset': dataset,
                    'video': video_name,
                    'config_path': str(config_dir),
                    'config_name': config_dir.name
                })

    # Create DataFrame from collected records
    df = pd.DataFrame(config_records)

    if verbose:
        print(f"\nFound {len(df)} configurations across {df['dataset'].nunique()} datasets")
        print(f"Datasets: {df['dataset'].unique().tolist()}")

    return df


def parse_config_names(df: pd.DataFrame) -> pd.DataFrame:
    """
    Parse configuration names to extract classifier, tilesize, and tilepadding.

    Args:
        df: DataFrame with config_name column

    Returns:
        DataFrame with added columns: classifier, tilesize, tilepadding
    """
    # Split config names using pandas string operations
    config_parts = df['config_name'].str.split('_', n=2, expand=True)
    config_parts.columns = ['classifier', 'tilesize', 'tilepadding']

    # Convert tilesize to int
    config_parts['tilesize'] = config_parts['tilesize'].astype(int)

    # Concatenate with original DataFrame
    result_df = pd.concat([df, config_parts], axis=1)

    return result_df


def count_images_for_path(config_path: str) -> int:
    """
    Count the number of compressed images in a configuration directory.

    Args:
        config_path: Path to configuration directory

    Returns:
        Number of .jpg files in the images subdirectory
    """
    # Use pathlib for cleaner path handling
    images_dir = Path(config_path) / 'images'

    if not images_dir.is_dir():
        return 0

    # Count .jpg files using glob
    jpg_files = list(images_dir.glob('*.jpg'))
    return len(jpg_files)


def count_tiles_for_path(config_path: str) -> Tuple[int, int]:
    """
    Count empty and occupied tiles from index_maps in a configuration directory.

    Args:
        config_path: Path to configuration directory

    Returns:
        Tuple of (empty_tiles, occupied_tiles)
    """
    # Use pathlib for cleaner path handling
    index_maps_dir = Path(config_path) / 'index_maps'

    if not index_maps_dir.is_dir():
        return 0, 0

    # Get all .npy files
    npy_files = list(index_maps_dir.glob('*.npy'))

    if not npy_files:
        return 0, 0

    # Load all index maps and compute counts using vectorized numpy operations
    empty_tiles = 0
    occupied_tiles = 0

    for npy_file in npy_files:
        try:
            # Load the index map
            index_map = np.load(str(npy_file))

            # Use numpy vectorized operations for counting
            empty_tiles += np.sum(index_map == 0)
            occupied_tiles += np.sum(index_map != 0)

        except Exception:
            # Skip files that can't be loaded
            continue

    return int(empty_tiles), int(occupied_tiles)


def get_video_total_frames(row: pd.Series) -> int:
    """
    Get the total number of frames for a video.

    Args:
        row: DataFrame row with 'dataset' and 'video' columns

    Returns:
        Total number of frames in the video
    """
    try:
        # Use the get_video_frame_count function from utilities
        return get_video_frame_count(row['dataset'], row['video'])
    except Exception:
        # Return 0 if video cannot be found or opened
        return 0


def compute_metrics(df: pd.DataFrame, verbose: bool = False) -> pd.DataFrame:
    """
    Compute image counts and tile counts for all configurations using pandas apply.

    Args:
        df: DataFrame with config_path column
        verbose: Whether to show progress bar

    Returns:
        DataFrame with added columns: num_images, empty_tiles, occupied_tiles,
                                      total_tiles, occupancy_ratio, total_frames
    """
    if verbose:
        print("\nComputing video frame counts...")

    # Get total frames for each video (only need to compute once per unique dataset+video combination)
    unique_videos = df[['dataset', 'video']].drop_duplicates()
    tqdm.pandas(desc="Getting video frame counts", disable=not verbose)
    unique_videos['total_frames'] = unique_videos.progress_apply(get_video_total_frames, axis=1) if verbose else unique_videos.apply(get_video_total_frames, axis=1)

    # Merge the total_frames back into the main DataFrame
    df = df.merge(unique_videos[['dataset', 'video', 'total_frames']], on=['dataset', 'video'], how='left')

    if verbose:
        print("Computing image counts...")

    # Apply count_images function to each row
    tqdm.pandas(desc="Counting images", disable=not verbose)
    df['num_images'] = df['config_path'].progress_apply(count_images_for_path) if verbose else df['config_path'].apply(count_images_for_path)

    if verbose:
        print("Computing tile counts...")

    # Apply count_tiles function and expand the tuple result into two columns
    tqdm.pandas(desc="Counting tiles", disable=not verbose)
    tile_counts = df['config_path'].progress_apply(count_tiles_for_path) if verbose else df['config_path'].apply(count_tiles_for_path)
    df[['empty_tiles', 'occupied_tiles']] = pd.DataFrame(tile_counts.tolist(), index=df.index)

    # Compute derived metrics using vectorized pandas operations
    df['total_tiles'] = df['empty_tiles'] + df['occupied_tiles']
    df['occupancy_ratio'] = df['occupied_tiles'] / df['total_tiles'].where(df['total_tiles'] > 0, 1)

    return df


def save_comparison_tables(df: pd.DataFrame, verbose: bool = False):
    """
    Save comparison tables as CSV files for each dataset.

    Args:
        df: DataFrame with all metrics
        verbose: Whether to print verbose output
    """
    # Group by dataset and save separate CSVs
    for dataset, group_df in df.groupby('dataset'):
        # Create output directory
        output_dir = Path(CACHE_DIR) / dataset / 'evaluation' / OUTPUT_DIR
        output_dir.mkdir(parents=True, exist_ok=True)

        # Select columns for image counts table
        image_cols = ['dataset', 'video', 'classifier', 'tilesize', 'tilepadding', 'num_images', 'total_frames']
        image_df = group_df[image_cols].copy()

        # Select columns for tile counts table
        tile_cols = ['dataset', 'video', 'classifier', 'tilesize', 'tilepadding',
                     'empty_tiles', 'occupied_tiles', 'total_tiles', 'occupancy_ratio']
        tile_df = group_df[tile_cols].copy()

        # Save image counts table
        image_csv_path = output_dir / 'image_counts_comparison.csv'
        image_df.to_csv(image_csv_path, index=False)
        print(f"\nSaved image counts table: {image_csv_path}")

        if verbose:
            print(f"  Total configurations: {len(image_df)}")
            print(f"  Total images: {image_df['num_images'].sum()}")
            print(f"  Total frames: {image_df['total_frames'].sum()}")

        # Save tile counts table
        tile_csv_path = output_dir / 'tile_counts_comparison.csv'
        tile_df.to_csv(tile_csv_path, index=False)
        print(f"Saved tile counts table: {tile_csv_path}")

        if verbose:
            print(f"  Total configurations: {len(tile_df)}")
            print(f"  Total tiles: {tile_df['total_tiles'].sum()}")
            print(f"  Average occupancy ratio: {tile_df['occupancy_ratio'].mean():.4f}")


def main(args):
    """
    Main function to compare compression results.

    Args:
        args: Parsed command line arguments
    """
    if args.verbose:
        print("Starting compression comparison analysis...")
        print(f"Cache directory: {CACHE_DIR}")
        print(f"Datasets to analyze: {args.datasets}")

    # Step 1: Build DataFrame of all configuration paths
    df = build_config_paths_dataframe(args.datasets, args.verbose)

    if df.empty:
        print("\nNo compression data found for any dataset!")
        return

    # Step 2: Parse configuration names to extract classifier, tilesize, tilepadding
    df = parse_config_names(df)

    # Step 3: Compute metrics (image counts and tile counts) using pandas apply
    df = compute_metrics(df, args.verbose)

    # Step 4: Save comparison tables grouped by dataset
    save_comparison_tables(df, args.verbose)

    # Step 5: Print summary using pandas aggregation functions
    print(f"\nSummary:")
    print(f"  Total datasets processed: {df['dataset'].nunique()}")
    print(f"  Total configurations analyzed: {len(df)}")
    print(f"  Total compressed images: {df['num_images'].sum()}")
    print(f"  Total tiles: {df['total_tiles'].sum()}")


if __name__ == '__main__':
    args = parse_args()
    main(args)